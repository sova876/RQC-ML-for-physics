{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ð°)  $L_1$, $L_2$ - Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "L2:\n",
    "                 $$\n",
    "    L_{reg} \\left(X, \\vec{y}, \\vec{w}\\right) =\\left\\| \\vec{y} - X \\vec{w} \\right\\|_2^2  + \\frac{\\lambda}{2} \\left\\| \\vec{w} \\right\\|^2\n",
    "          $$\n",
    "       \n",
    "L1:\n",
    "$$\n",
    "    L_{reg} \\left(X, \\vec{y}, \\vec{w}\\right) =\\left\\| \\vec{y} - X \\vec{w} \\right\\|_2^2  + \\frac{\\lambda}{2} \\left\\| \\vec{w} \\right\\|_1\n",
    "          $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "##### implementation in pytorch\n",
    "model = nn.Sequential(nn.Linear(10,10),nn.ReLU())\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pytorch class\n",
    "```python\n",
    "    nn.Dropout(p=p)\n",
    " ```\n",
    "In regime \n",
    "```python\n",
    "model.train(True)\n",
    "``` \n",
    "dropout is used\n",
    "\n",
    "In regime \n",
    "```python\n",
    "model.train(False)\n",
    "``` \n",
    "dropout is not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# data generation\n",
    "N = 50\n",
    "noise = 0.3\n",
    "\n",
    "X_train = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
    "Y_train = X_train + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
    "\n",
    "X_test = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
    "Y_test = X_test + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
    "\n",
    "\n",
    "plt.scatter(X_train.data.numpy(), Y_train.data.numpy(), c='purple', alpha=0.5, label='train')\n",
    "plt.scatter(X_test.data.numpy(), Y_test.data.numpy(), c='yellow', alpha=0.5, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, drop_p, N_h):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         NN:Linear[1->Nh],Dropout[p],Linear[N_h->N_h],Dropout[p],Linear[N_h->1]\n",
    "        self.fc = nn.Sequential(\n",
    "                    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "# model definition\n",
    "N_h = 100\n",
    "lr = 0.005\n",
    "eps = 1e-2\n",
    "\n",
    "model = \n",
    "opt = \n",
    "\n",
    "model_L2 = \n",
    "opt_L2 = \n",
    "\n",
    "model_dropout = \n",
    "opt_dropout = \n",
    "\n",
    "loss_fn = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "max_epochs = 1000\n",
    "eval_epoch = 25\n",
    "\n",
    "loss_, test_loss_, loss_L2_, test_loss_L2_,loss_dropout_, test_loss_dropout_ = [],[],[],[],[],[]\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    if epoch % eval_epoch == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        model_L2.eval()\n",
    "        model_dropout.eval()\n",
    "        \n",
    "        test_pred = model(X_test)\n",
    "        test_loss = loss_fn(test_pred, Y_test)\n",
    "        test_loss_.append(test_loss.item())\n",
    "        \n",
    "        test_pred_L2 = model_L2(X_test)\n",
    "        test_loss_L2 = loss_fn(test_pred_L2, Y_test)\n",
    "        test_loss_L2_.append(test_loss_L2.item())\n",
    "        \n",
    "        test_pred_dropout = model_dropout(X_test)\n",
    "        test_loss_dropout = loss_fn(test_pred_dropout, Y_test)\n",
    "        test_loss_dropout_.append(test_loss_dropout.item())\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        plt.scatter(X_train.data.numpy(), Y_train.data.numpy(), c='purple', alpha=0.5, label='train')\n",
    "        plt.scatter(X_test.data.numpy(), Y_test.data.numpy(), c='yellow', alpha=0.5, label='test')\n",
    "        plt.plot(X_test.data.numpy(), test_pred.data.numpy(), c='red',linestyle='-', lw=3, label='normal')\n",
    "        plt.plot(X_test.data.numpy(), test_pred_L2.data.numpy(), c='black',linestyle=':', lw=3, label='L2')\n",
    "        plt.plot(X_test.data.numpy(), test_pred_dropout.data.numpy(), c='blue',linestyle='--', lw=3,  label='dropout')\n",
    "        \n",
    "        plt.title('Epoch %d, Loss = %0.4f, Loss_L2 = %0.4f, Loss with dropout = %0.4f' % \n",
    "                  (epoch, test_loss,test_loss_L2, test_loss_dropout))\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        model.train()\n",
    "        model_L2.train()\n",
    "        model_dropout.train()\n",
    "    \n",
    "    pred = model(X_train) \n",
    "    loss = loss_fn(pred, Y_train)\n",
    "    loss_.append(loss.item())\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    pred_L2 = model_L2(X_train) \n",
    "    loss_L2 = loss_fn(pred_L2, Y_train)\n",
    "    loss_L2_.append(loss_L2.item())\n",
    "    opt_L2.zero_grad()\n",
    "    loss_L2.backward()\n",
    "    opt_L2.step()\n",
    "    \n",
    "    pred_dropout = model_dropout(X_train)\n",
    "    loss_dropout = loss_fn(pred_dropout, Y_train)\n",
    "    loss_dropout_.append(loss_dropout.item())\n",
    "    opt_dropout.zero_grad()\n",
    "    loss_dropout.backward()\n",
    "    opt_dropout.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize = (20,5))\n",
    "plot_x = np.arange(0,max_epochs,eval_epoch)\n",
    "\n",
    "ax1.plot(loss_, label='train_normal')\n",
    "ax1.plot(plot_x,test_loss_, label='test_normal')\n",
    "ax1.grid()\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(loss_L2_, label='train_L2')\n",
    "ax2.plot(plot_x,test_loss_L2_, label='test_L2')\n",
    "ax2.grid()\n",
    "ax2.set_title('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(loss_dropout_, label='train_dropout')\n",
    "ax3.plot(plot_x,test_loss_dropout_, label='test_dropout')\n",
    "ax3.grid()\n",
    "ax3.set_title('Loss')\n",
    "ax3.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<img src=\"./images/11.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image augmentation:\n",
    "\n",
    "<img src=\"./images/12.png\" >\n",
    "<img src=\"./images/8.png\" >\n",
    "<img src=\"./images/9.png\" >\n",
    "\n",
    "```python\n",
    "# use basic transformations from pytorch\n",
    "import torchvision.transforms as transform \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation in pytorch:\n",
    "\n",
    "_https://colab.research.google.com/drive/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll_ \n",
    "    \n",
    "\n",
    "_https://modelzoo.co/model/data-augmentation-and-sampling-for-pytorch_\n",
    "    \n",
    "_https://medium.com/secure-and-private-ai-writing-challenge/data-augmentation-increases-accuracy-of-your-model-but-how-aa1913468722_\n",
    "  \n",
    "\n",
    "<cite>https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</cite>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
